{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "\n",
    "from sklearn import svm, linear_model, neighbors\n",
    "from sklearn import tree, ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numbers\n",
    "def multimetric_score(estimator, X_test, y_test, scorers):\n",
    "    \"\"\"Return a dict of score for multimetric scoring\"\"\"\n",
    "    scores = {}\n",
    "    for name, scorer in scorers.items():\n",
    "        if y_test is None:\n",
    "            score = scorer(estimator, X_test)\n",
    "        else:\n",
    "            score = scorer(estimator, X_test, y_test)\n",
    "\n",
    "        if hasattr(score, 'item'):\n",
    "            try:\n",
    "                # e.g. unwrap memmapped scalars\n",
    "                score = score.item()\n",
    "            except ValueError:\n",
    "                # non-scalar?\n",
    "                pass\n",
    "        scores[name] = score\n",
    "\n",
    "        if not isinstance(score, numbers.Number):\n",
    "            raise ValueError(\"scoring must return a number, got %s (%s) \"\n",
    "                             \"instead. (scorer=%s)\"\n",
    "                             % (str(score), type(score), name))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addLinkToNetwork(net,source, target):\n",
    "    if source in net:\n",
    "        if target not in net[source]:  \n",
    "            net[source].append(target)\n",
    "    else:\n",
    "        net[source] =[target]\n",
    "\n",
    "def removeLinkToNetwork(net, source, target):\n",
    "    if source in net:\n",
    "        if target in net[source]:\n",
    "            net[source].remove(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getNeighbors(net, x):\n",
    "    if x in net:\n",
    "        return net[x]\n",
    "    else:\n",
    "        return []\n",
    "    \n",
    "def nStepNeighbors(net, x, max_length):\n",
    "    Found = dict()\n",
    "    Found[x] = True\n",
    "    NewSearch = []\n",
    "    NewSearch.append(x)\n",
    "    for curDeg in range(max_length):\n",
    "        #print \"Iteration ----------\",curDeg\n",
    "        OldSearch=[]\n",
    "        while len(NewSearch) != 0:\t\t\n",
    "            OldSearch.append( NewSearch.pop())\n",
    "        \n",
    "        while len(OldSearch) != 0:\n",
    "            vi = OldSearch.pop()\n",
    "            \n",
    "            for vj in getLinks(net,vi):\n",
    "                if vj not in Found:\n",
    "                    Found[vj]=True\n",
    "                    NewSearch.append(vj)\n",
    "    \n",
    "    return Found.keys()\n",
    "    \n",
    "def getCommonNeighborsOfNeighbors(net, x):\n",
    "    neighbors = list() \n",
    "    if x in net:\n",
    "        for c in getNeighbors_(net, x):\n",
    "            neighbors.append( set(getNeighbors_(net, c)))\n",
    "    \n",
    "        if len (neighbors) == 0: return []\n",
    "        if len (neighbors) == 1: return neighbors[0]\n",
    "        common =set.intersection(*neighbors)\n",
    "        return common\n",
    "    return []\n",
    "\n",
    "def commonNeighbors(net, x, y, weights={}):\n",
    "    if x== y:\n",
    "        return len(getNeighbors(net,x))\n",
    "\n",
    "    commons =set(getNeighbors(net,x)).intersection(getNeighbors(net,y))\n",
    "    return len(commons)\n",
    "\n",
    "def jaccard(net,x,y,weights={}):\n",
    "    if x == y:\n",
    "        return 1\n",
    "\n",
    "    commons =set(getNeighbors(net,x)).intersection(getNeighbors(net,y))\n",
    "    unions = set(getNeighbors(net,x)).union(getNeighbors(net,y))\n",
    "    if len(unions) == 0:\n",
    "        return 0.0\n",
    "    return float(len(commons))/len(unions)\n",
    "def adamic(net,x,y,weights={}):\n",
    "    commons =set(getNeighbors(net,x)).intersection(getNeighbors(net,y))\n",
    "    score =0.0\n",
    "    for n in commons:\n",
    "        score += 1.0/math.log(float(len(getNeighbors(net,n))))\n",
    "\n",
    "    return score\n",
    "\n",
    "def propFlowNet(net, start, end, weights={}):\n",
    "    return 1\n",
    "    global  allRanks\n",
    "    if start not in allRanks:\n",
    "        allRanks[start]=propFlow(net,start,weights)\n",
    "    #print start,len(allRanks[start])\n",
    "    #print net[start]\n",
    "    if start in allRanks:\n",
    "        if end in allRanks[start]:\n",
    "            return allRanks[start][end]\n",
    "        else:\n",
    "            return 0.0\n",
    "    return allRanks[start][end]\n",
    "\n",
    "def propFlow(net, vs, weights={},  max_length=3, decayFactor= 0.15, topN=10, itemtype=\"mo\" ):\n",
    "\n",
    "    Found=dict()\n",
    "    NewSearch=[]\n",
    "    S=dict()\n",
    "    Found[vs] =True\n",
    "    NewSearch.append(vs)\n",
    "    S[vs]=1.0\n",
    "    #print \"start node\",vs\n",
    "    #print net[vs]\n",
    "    for curDeg in range(max_length):\n",
    "        #print \"Iteration ----------\",curDeg\n",
    "        OldSearch=[]\n",
    "        while len(NewSearch) != 0:\t\t\n",
    "            OldSearch.append( NewSearch.pop())\n",
    "        while len(OldSearch) != 0:\n",
    "            vi =OldSearch.pop()\n",
    "            NodeInput =S[vi]\n",
    "            SumOutput =0\n",
    "            for vj in getNeighbors(net,vi):\n",
    "                if (vi,vj) in weights:\n",
    "                    weight =weights[(vi,vj)]\n",
    "                else:\n",
    "                    weight=1.0\n",
    "                SumOutput +=weight\n",
    "            Flow =0\n",
    "            if SumOutput ==0:\n",
    "                SumOutput=1.0\n",
    "\n",
    "            for vj in getNeighbors(net,vi):\n",
    "                if (vi,vj) in weights:\n",
    "                    weight =weights[(vi,vj)]\n",
    "                else:\n",
    "                    weight=1.0\n",
    "\n",
    "                Flow = NodeInput * weight*(1-decayFactor)/SumOutput\n",
    "                if vj in S:\n",
    "                    S[vj] += Flow\n",
    "                else:\n",
    "                    S[vj] =Flow\n",
    "\n",
    "                #print (vj, Flow)\n",
    "                #print net[vj]\n",
    "                if vj not in Found:\n",
    "                    Found[vj]=True\n",
    "                    NewSearch.append(vj)\n",
    "    #print S\n",
    "    return S\t\n",
    "\n",
    "def personalizedPagerank(net, start=None, damping_factor=0.85,max_iter=100,min_delta=0.00001, weights={}):\n",
    "\n",
    "    nodes= net.keys()\n",
    "    numNodes = len(nodes)\n",
    "    if numNodes == 0:\n",
    "        return {}\n",
    "    min_value= (1.0-damping_factor)/numNodes\n",
    "    pagerank = dict.fromkeys(nodes,1.0/numNodes)\n",
    "    for i in range(max_iter):\n",
    "        diff =0\n",
    "        for node in nodes:\n",
    "            rank = 0.0\n",
    "            for neigh in net[node]:\n",
    "                if (node,neigh) in weights:\n",
    "                    weight =weights[(node,neigh)]\n",
    "                else:\n",
    "                    weight=1.0\n",
    "                rank += damping_factor*weight*pagerank[neigh]/len(net[neigh])\n",
    "\n",
    "            if type(start)==list:\n",
    "                if  node in start:\n",
    "                    rank +=min_value\t\n",
    "            else:\n",
    "                if start == node:\n",
    "                    rank +=min_value\n",
    "\n",
    "            diff += abs(pagerank[node]-rank)\n",
    "            pagerank[node]=rank\n",
    "        if diff < min_delta:\n",
    "            break\n",
    "\n",
    "    return pagerank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "goldindfile = \"../data/input/unified-gold-standard-umls.txt\"\n",
    "embdfilename = \"vectors/Entity2Vec_sg_200_5_5_15_2_500_d5_uniform.txt\"\n",
    "emb_df = pd.read_csv(embdfilename, delimiter='\\t') \n",
    "\n",
    "gold_df= pd.read_csv(goldindfile, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity</th>\n",
       "      <th>feature0</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>...</th>\n",
       "      <th>feature190</th>\n",
       "      <th>feature191</th>\n",
       "      <th>feature192</th>\n",
       "      <th>feature193</th>\n",
       "      <th>feature194</th>\n",
       "      <th>feature195</th>\n",
       "      <th>feature196</th>\n",
       "      <th>feature197</th>\n",
       "      <th>feature198</th>\n",
       "      <th>feature199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DB02133</td>\n",
       "      <td>-0.051658</td>\n",
       "      <td>0.163778</td>\n",
       "      <td>-0.361194</td>\n",
       "      <td>-0.087759</td>\n",
       "      <td>0.297820</td>\n",
       "      <td>0.305669</td>\n",
       "      <td>0.236298</td>\n",
       "      <td>0.254304</td>\n",
       "      <td>0.135926</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.507540</td>\n",
       "      <td>-0.126325</td>\n",
       "      <td>0.208918</td>\n",
       "      <td>0.078276</td>\n",
       "      <td>-0.395061</td>\n",
       "      <td>-0.024653</td>\n",
       "      <td>0.245934</td>\n",
       "      <td>-0.024440</td>\n",
       "      <td>0.300537</td>\n",
       "      <td>0.041316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fingerprint10</td>\n",
       "      <td>0.098235</td>\n",
       "      <td>0.485436</td>\n",
       "      <td>-0.309485</td>\n",
       "      <td>-0.256898</td>\n",
       "      <td>0.789238</td>\n",
       "      <td>0.328992</td>\n",
       "      <td>0.827521</td>\n",
       "      <td>-0.150584</td>\n",
       "      <td>-0.397627</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.523152</td>\n",
       "      <td>-0.109714</td>\n",
       "      <td>0.122435</td>\n",
       "      <td>-0.000810</td>\n",
       "      <td>-0.030355</td>\n",
       "      <td>0.136024</td>\n",
       "      <td>0.280323</td>\n",
       "      <td>-0.314951</td>\n",
       "      <td>0.541641</td>\n",
       "      <td>0.045266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DB02863</td>\n",
       "      <td>-0.015989</td>\n",
       "      <td>0.141269</td>\n",
       "      <td>-0.162110</td>\n",
       "      <td>0.091442</td>\n",
       "      <td>0.441140</td>\n",
       "      <td>0.293197</td>\n",
       "      <td>0.156931</td>\n",
       "      <td>0.195844</td>\n",
       "      <td>0.298615</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.407804</td>\n",
       "      <td>-0.057749</td>\n",
       "      <td>0.091881</td>\n",
       "      <td>-0.127052</td>\n",
       "      <td>-0.465435</td>\n",
       "      <td>-0.146370</td>\n",
       "      <td>0.241991</td>\n",
       "      <td>0.223220</td>\n",
       "      <td>0.206277</td>\n",
       "      <td>-0.025753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DB00258</td>\n",
       "      <td>0.203198</td>\n",
       "      <td>0.468460</td>\n",
       "      <td>-0.333941</td>\n",
       "      <td>0.534330</td>\n",
       "      <td>0.675704</td>\n",
       "      <td>-0.003532</td>\n",
       "      <td>0.554302</td>\n",
       "      <td>-0.210865</td>\n",
       "      <td>-0.257030</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.178686</td>\n",
       "      <td>-0.310188</td>\n",
       "      <td>0.208252</td>\n",
       "      <td>-0.585612</td>\n",
       "      <td>-0.160281</td>\n",
       "      <td>-0.080312</td>\n",
       "      <td>0.326872</td>\n",
       "      <td>0.102249</td>\n",
       "      <td>-0.090835</td>\n",
       "      <td>-0.027320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DB08913</td>\n",
       "      <td>0.257988</td>\n",
       "      <td>0.621600</td>\n",
       "      <td>-0.641045</td>\n",
       "      <td>0.271267</td>\n",
       "      <td>0.463862</td>\n",
       "      <td>-0.259994</td>\n",
       "      <td>0.584031</td>\n",
       "      <td>0.013617</td>\n",
       "      <td>-0.112262</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.528301</td>\n",
       "      <td>0.071888</td>\n",
       "      <td>-0.333639</td>\n",
       "      <td>-0.108896</td>\n",
       "      <td>0.123948</td>\n",
       "      <td>-0.096030</td>\n",
       "      <td>0.363442</td>\n",
       "      <td>0.126367</td>\n",
       "      <td>0.199852</td>\n",
       "      <td>-0.012021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Entity  feature0  feature1  feature2  feature3  feature4  feature5  \\\n",
       "0        DB02133 -0.051658  0.163778 -0.361194 -0.087759  0.297820  0.305669   \n",
       "1  Fingerprint10  0.098235  0.485436 -0.309485 -0.256898  0.789238  0.328992   \n",
       "2        DB02863 -0.015989  0.141269 -0.162110  0.091442  0.441140  0.293197   \n",
       "3        DB00258  0.203198  0.468460 -0.333941  0.534330  0.675704 -0.003532   \n",
       "4        DB08913  0.257988  0.621600 -0.641045  0.271267  0.463862 -0.259994   \n",
       "\n",
       "   feature6  feature7  feature8     ...      feature190  feature191  \\\n",
       "0  0.236298  0.254304  0.135926     ...       -0.507540   -0.126325   \n",
       "1  0.827521 -0.150584 -0.397627     ...       -0.523152   -0.109714   \n",
       "2  0.156931  0.195844  0.298615     ...       -0.407804   -0.057749   \n",
       "3  0.554302 -0.210865 -0.257030     ...       -0.178686   -0.310188   \n",
       "4  0.584031  0.013617 -0.112262     ...       -0.528301    0.071888   \n",
       "\n",
       "   feature192  feature193  feature194  feature195  feature196  feature197  \\\n",
       "0    0.208918    0.078276   -0.395061   -0.024653    0.245934   -0.024440   \n",
       "1    0.122435   -0.000810   -0.030355    0.136024    0.280323   -0.314951   \n",
       "2    0.091881   -0.127052   -0.465435   -0.146370    0.241991    0.223220   \n",
       "3    0.208252   -0.585612   -0.160281   -0.080312    0.326872    0.102249   \n",
       "4   -0.333639   -0.108896    0.123948   -0.096030    0.363442    0.126367   \n",
       "\n",
       "   feature198  feature199  \n",
       "0    0.300537    0.041316  \n",
       "1    0.541641    0.045266  \n",
       "2    0.206277   -0.025753  \n",
       "3   -0.090835   -0.027320  \n",
       "4    0.199852   -0.012021  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bio_entities = emb_df.Entity.unique()\n",
    "bio_entities=list(bio_entities)\n",
    "\n",
    "drugDiseaseKnown = set([tuple(x) for x in  gold_df[['Drug','Disease']].values])\n",
    "\n",
    "positives = gold_df[['Drug','Disease']]\n",
    "positives = positives[positives.Drug.isin(bio_entities) & positives.Disease.isin(bio_entities)]\n",
    "positives['Class'] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "commonDiseases 1377\n",
      "commonDrugs 1453\n",
      "INDI size:  7846\n",
      "non-INDI size:  1992935\n",
      "Train size:  23538\n"
     ]
    }
   ],
   "source": [
    "drugDiseaseKnown = set([tuple(x) for x in  positives[['Drug','Disease']].values])\n",
    "pairs=[]\n",
    "classes=[]\n",
    "drugs = set(positives['Drug'].unique())\n",
    "diseases = set(positives['Disease'].unique())\n",
    "print (\"commonDiseases\",len(diseases))\n",
    "print (\"commonDrugs\",len(drugs))\n",
    "for dr in drugs:\n",
    "    for di in diseases:\n",
    "        if (dr,di)  in drugDiseaseKnown:\n",
    "            cls=1\n",
    "        else:\n",
    "            cls=0\n",
    "        pairs.append((dr,di))\n",
    "        classes.append(cls)\n",
    "\n",
    "pairs = np.array(pairs)        \n",
    "classes = np.array(classes)\n",
    "\n",
    "indices = np.where(classes == 1)\n",
    "positives = pd.DataFrame(list(zip(pairs[indices][:,0],pairs[indices][:,1],classes[indices])), columns=['Drug','Disease','Class'])\n",
    "\n",
    "indices = np.where(classes == 0)\n",
    "all_negatives = pd.DataFrame(list(zip(pairs[indices][:,0],pairs[indices][:,1],classes[indices])), columns=['Drug','Disease','Class'])\n",
    "\n",
    "print(\"INDI size: \", len(positives))\n",
    "print(\"non-INDI size: \",len(all_negatives))\n",
    "\n",
    "negatives = all_negatives.sample(2*len(positives)) # for balanced class\n",
    "\n",
    "pair_df = pd.concat([positives,negatives], ignore_index=True)\n",
    "print(\"Train size: \", len(pair_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def netFeatureSet(net, n, n2, cls):\n",
    "    PF = propFlowNet(net,n, n2)\n",
    "    JC = jaccard(net,n,n2)\n",
    "    AA = adamic(net,n,n2)\n",
    "    CN = commonNeighbors(net,n,n2)\n",
    "    print (PF, JC, AA, CN)\n",
    "    return n, n2, cls, PF, JC, AA, CN\n",
    "\n",
    "def getNumberOfNeighors(G, x):\n",
    "    count = 0\n",
    "    for y in G[x]:\n",
    "        count += len(G[y])\n",
    "    return count\n",
    "\n",
    "def adamic(net,x,y,weights={}):\n",
    "    commons =set(getNeighbors(net,x)).intersection(getNeighbors(net,y))\n",
    "    score =0.0\n",
    "    for n in commons:\n",
    "        score += 1.0/math.log(float(len(getNeighbors(net,n))))\n",
    "\n",
    "    return score\n",
    "\n",
    "def getNumNeighs(G, x):\n",
    "    if x in G:\n",
    "        return len(G[x])\n",
    "    return 0\n",
    "\n",
    "def prefenAttach(G, n, n2):\n",
    "    if n in G and n2 in G:\n",
    "        return len(G[n])*len(G[n2])\n",
    "    return 0\n",
    "\n",
    "def PF_sim(G, x, y, weights ={}):\n",
    "    addLater = False\n",
    "    if G.has_edge(x,y):\n",
    "        G.remove_edge(x,y)\n",
    "        addLater = True\n",
    "    PF = propFlow(G,x,max_length=5, weights=weights)\n",
    "    if addLater:\n",
    "        G.add_edge(x,y)\n",
    "    \n",
    "    if y in PF:\n",
    "        return PF[y]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def networkXFeatureSet(G, source, target, cls):\n",
    "    if source in G.nodes and target in G.node:\n",
    "        paths = nx.all_simple_paths(G, source, target, cutoff=3) # paths with length 3 between s and t \n",
    "        num_paths = len(list(paths))\n",
    "    else:\n",
    "        num_paths = 0\n",
    "     \n",
    "    if source in G.nodes:\n",
    "        all_paths_3 = getNumberOfNeighors(G, source)\n",
    "    else:\n",
    "        all_paths_3 = 1 \n",
    "    total_neigh_st= getNumNeighs(G,source)+ getNumNeighs(G,target) \n",
    "    \n",
    "    if total_neigh_st <= 1:\n",
    "        total_neigh_st += 0.5\n",
    "        \n",
    "    CN = num_paths\n",
    "    JC = num_paths/all_paths_3\n",
    "    PF = PF_sim(G, source, target) \n",
    "    #PA = prefenAttach(G, source, target)\n",
    "    AA = num_paths/math.log(float(total_neigh_st))\n",
    "    #print (PF, JC, AA, CN, cls)\n",
    "    return source, target, cls, PF, JC, AA, CN\n",
    "\n",
    "def linkPredSpark(bc_graph, pairs, classes):\n",
    "    global  allRanks\n",
    "    allRanks ={}\n",
    "\n",
    "    pairList = list(zip(pairs[:,0],pairs[:,1],classes))\n",
    "\n",
    "    start_time =time.time()\n",
    "    rdd = sc.parallelize(pairList).map(lambda x: networkXFeatureSet(bc_graph.value, x[0], x[1], x[2] ))\n",
    "    pair_df = rdd.collect()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    #print ('Time elapsed to generate walks:',time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n",
    "    return pd.DataFrame(pair_df, columns=['Drug','Disease','Class', 'PF','JC','AA','CN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkConf, SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SparkContext master=local[6] appName=pyspark-shell>\n"
     ]
    }
   ],
   "source": [
    "config = SparkConf()\n",
    "config.setMaster(\"local[6]\")\n",
    "#config.set(\"spark.executor.memory\", \"2g\")\n",
    "sc = SparkContext(conf=config)\n",
    "print (sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_scores(clf, X_new, y_new):\n",
    "\n",
    "    scoring = ['precision', 'recall', 'accuracy', 'roc_auc', 'f1', 'average_precision']\n",
    "    scorers, multimetric = metrics.scorer._check_multimetric_scoring(clf, scoring=scoring)\n",
    "    #print(scorers)\n",
    "    scores = multimetric_score(clf, X_new, y_new, scorers)\n",
    "    return scores\n",
    "\n",
    "\n",
    "def crossvalid(train_df, test_df): \n",
    "    features_cols= train_df.columns.difference(['Drug','Disease' ,'Class', 'Entity_x', 'Entity_y'])\n",
    "    X=train_df[features_cols].values\n",
    "    y=train_df['Class'].values.ravel()\n",
    "\n",
    "    X_new=test_df[features_cols].values\n",
    "    y_new=test_df['Class'].values.ravel()\n",
    "\n",
    "    nb_model = GaussianNB()\n",
    "    nb_model.fit(X,y)\n",
    "    nb_scores = get_scores(nb_model, X_new, y_new)\n",
    "    \n",
    "    logistic_model = linear_model.LogisticRegression()\n",
    "    logistic_model.fit(X,y)\n",
    "    lr_scores = get_scores(logistic_model, X_new, y_new)\n",
    "    \n",
    "    rf_model = ensemble.RandomForestClassifier(n_estimators=200, n_jobs=-1)\n",
    "    rf_model.fit(X,y)\n",
    "    rf_scores = get_scores(rf_model, X_new, y_new)\n",
    "    \n",
    "    #clf = ensemble.RandomForestClassifier(n_estimators=100\n",
    "    return nb_scores,lr_scores, rf_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runa10foldcv(pair_df, emb_df,  cv):\n",
    "    nb_scores_df = pd.DataFrame()\n",
    "    lr_scores_df = pd.DataFrame()\n",
    "    rf_scores_df = pd.DataFrame()\n",
    "    \n",
    "    for i, (train_idx, test_idx) in enumerate(cv):\n",
    "\n",
    "        train = pair_df.loc[train_idx]\n",
    "        test = pair_df.loc[test_idx]\n",
    "        G = nx.Graph()\n",
    "        for index, row in train[train.Class == 1 ].iterrows():\n",
    "            drug=row['Drug']\n",
    "            disease=row['Disease']\n",
    "            G.add_edge(drug, disease)\n",
    "\n",
    "\n",
    "        bc_net=sc.broadcast(G)\n",
    "        #print (len(bc_net.value))\n",
    "\n",
    "        test_df = linkPredSpark(bc_net, test[['Drug','Disease']].values, test.Class)\n",
    "        train_df = linkPredSpark(bc_net, train[['Drug','Disease']].values, train.Class)\n",
    "\n",
    "        train_df = train_df.merge(emb_df, left_on='Drug', right_on='Entity').merge(emb_df, left_on='Disease', right_on='Entity')\n",
    "        test_df =  test_df.merge(emb_df, left_on='Drug', right_on='Entity').merge(emb_df, left_on='Disease', right_on='Entity')\n",
    "\n",
    "        nb_scores,lr_scores, rf_scores = crossvalid(train_df, test_df)\n",
    "\n",
    "        nb_scores_df = nb_scores_df.append(nb_scores, ignore_index=True)\n",
    "        lr_scores_df = lr_scores_df.append(lr_scores, ignore_index=True)\n",
    "        rf_scores_df = rf_scores_df.append(rf_scores, ignore_index=True)\n",
    "    return nb_scores_df,lr_scores_df, rf_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n",
      "fold 6\n",
      "fold 7\n",
      "fold 8\n",
      "fold 9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "#skf = StratifiedShuffleSplit(n_splits=10)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "n_run = 10\n",
    "nb_scores_df = pd.DataFrame()\n",
    "lr_scores_df = pd.DataFrame()\n",
    "rf_scores_df = pd.DataFrame()\n",
    "for k in range(n_run):\n",
    "    print ('run',k)\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=k)\n",
    "    cv = skf.split(pair_df, pair_df.Class)\n",
    "    nb_scores,lr_scores, rf_scores = runa10foldcv(pair_df,emb_df,  cv)\n",
    "    nb_scores_df = nb_scores_df.append(nb_scores.mean(), ignore_index=True)\n",
    "    lr_scores_df = lr_scores_df.append(lr_scores.mean(), ignore_index=True)\n",
    "    rf_scores_df = rf_scores_df.append(rf_scores.mean(), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outfolder='results/'\n",
    "if not os.path.isdir(outfolder):\n",
    "    os.mkdir(outfolder)\n",
    "\n",
    "nb_scores_df.to_csv(os.path.join(outfolder,'GEPDI_NETWORK_RDF2Vec_nb_results_pred_CV.csv'))\n",
    "lr_scores_df.to_csv(os.path.join(outfolder,'GEPDI_NETWORK_RDF2Vec_lr_results_pred_CV.csv'))\n",
    "rf_scores_df.to_csv(os.path.join(outfolder,'GEPDI_NETWORK_RDF2Vec_rf_results_pred_CV.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_scores_df = pd.DataFrame()\n",
    "all_scores_df = all_scores_df.append(lr_scores_df.mean(), ignore_index=True)\n",
    "all_scores_df = all_scores_df.append(nb_scores_df.mean(), ignore_index=True)\n",
    "all_scores_df = all_scores_df.append(rf_scores_df.mean(), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>average_precision</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.891614</td>\n",
       "      <td>0.912680</td>\n",
       "      <td>0.896054</td>\n",
       "      <td>0.927522</td>\n",
       "      <td>0.732132</td>\n",
       "      <td>0.818204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.882105</td>\n",
       "      <td>0.866904</td>\n",
       "      <td>0.848688</td>\n",
       "      <td>0.929408</td>\n",
       "      <td>0.699516</td>\n",
       "      <td>0.798114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.891155</td>\n",
       "      <td>0.925510</td>\n",
       "      <td>0.907602</td>\n",
       "      <td>0.862638</td>\n",
       "      <td>0.801263</td>\n",
       "      <td>0.830704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy   roc_auc  average_precision  precision    recall        f1\n",
       "0  0.891614  0.912680           0.896054   0.927522  0.732132  0.818204\n",
       "1  0.882105  0.866904           0.848688   0.929408  0.699516  0.798114\n",
       "2  0.891155  0.925510           0.907602   0.862638  0.801263  0.830704"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores_df[['accuracy','roc_auc','average_precision','precision','recall','f1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
