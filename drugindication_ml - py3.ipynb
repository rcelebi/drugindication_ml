{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree, ensemble\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.feature_selection import VarianceThreshold,SelectFromModel\n",
    "from sklearn import svm, linear_model, neighbors\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "import numpy\n",
    "from sklearn import cross_validation\n",
    "#from sklearn.metrics import roc_curve, auc, average_precision_score, confusion_matrix\n",
    "#from sklearn.metrics import roc_auc_score,accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import argparse\n",
    "import random\n",
    "import csv\n",
    "import numbers\n",
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics.scorer import _check_multimetric_scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createFeatureMat(pairs, classes, drug_df, disease_df, featureMatfile=None):\n",
    "    totalNumFeatures=drug_df.shape[1] + disease_df.shape[1]-2\n",
    "    drug_features = drug_df.columns.difference( ['Drug'] )\n",
    "    disease_features = disease_df.columns.difference( ['Disease'])\n",
    "    featureMatrix = numpy.empty((0,totalNumFeatures), int)\n",
    "    for pair,cls in zip(pairs,classes):\n",
    "        (dr,di)=pair\n",
    "        values1 = drug_df.loc[drug_df['Drug'] == dr][drug_features].values\n",
    "        values2 = disease_df.loc[disease_df['Disease']==di][disease_features].values\n",
    "        featureArray =numpy.append(values1,values2 )\n",
    "        featureMatrix=numpy.vstack([featureMatrix, featureArray])\n",
    "    return featureMatrix\n",
    "\n",
    "def multimetric_score(estimator, X_test, y_test, scorers):\n",
    "    \"\"\"Return a dict of score for multimetric scoring\"\"\"\n",
    "    scores = {}\n",
    "    for name, scorer in scorers.items():\n",
    "        if y_test is None:\n",
    "            score = scorer(estimator, X_test)\n",
    "        else:\n",
    "            score = scorer(estimator, X_test, y_test)\n",
    "\n",
    "        if hasattr(score, 'item'):\n",
    "            try:\n",
    "                # e.g. unwrap memmapped scalars\n",
    "                score = score.item()\n",
    "            except ValueError:\n",
    "                # non-scalar?\n",
    "                pass\n",
    "        scores[name] = score\n",
    "\n",
    "        if not isinstance(score, numbers.Number):\n",
    "            raise ValueError(\"scoring must return a number, got %s (%s) \"\n",
    "                             \"instead. (scorer=%s)\"\n",
    "                             % (str(score), type(score), name))\n",
    "    return scores\n",
    "\n",
    "def runModel( pairs, classes,  drug_df, disease_df , cv, n_subset, n_proportion, n_fold, model_type, model_fun, features, disjoint_cv, n_seed, n_setsel, verbose=True, output_f=None):\n",
    "    clf= get_classification_model(model_type, model_fun, n_seed)\n",
    "    all_auc = []\n",
    "    all_auprc = []\n",
    "    all_fs = []\n",
    "    le_drug = preprocessing.LabelEncoder()\n",
    "    le_dis = preprocessing.LabelEncoder()\n",
    "    le_drug.fit(pairs[:,0])\n",
    "    le_dis.fit(pairs[:,1])\n",
    "    \n",
    "    results = pd.DataFrame()\n",
    "\n",
    "    for i, (train, test) in enumerate(cv):\n",
    "        file_name = None # for saving results\n",
    "        pairs_train = pairs[train]\n",
    "        classes_train = classes[train]\n",
    "        pairs_test = pairs[test]\n",
    "        classes_test = classes[test]\n",
    "        \n",
    "        pairs_train_df = pd.DataFrame( list(zip(pairs[train,0],pairs[train,1],classes[train])),columns=['Drug','Disease','Class'])\n",
    "        train_df=pd.merge( pd.merge(drug_df,pairs_train_df, on='Drug'),disease_df,on='Disease')\n",
    "\n",
    "        train_df['Drug']=le_drug.transform(train_df['Drug'])\n",
    "        train_df['Disease']=le_dis.transform(train_df['Disease'])\n",
    "        features_cols= train_df.columns.difference(['Drug','Disease','Class'])\n",
    "        X=train_df[features_cols].values\n",
    "        y=train_df['Class'].values.ravel()\n",
    "\n",
    "        pairs_test_df = pd.DataFrame( list(zip(pairs[test,0],pairs[test,1],classes[test])),columns=['Drug','Disease','Class'])\n",
    "        test_df=pd.merge( pd.merge(drug_df,pairs_test_df, on='Drug'),disease_df,on='Disease')\n",
    "\n",
    "        test_df['Drug']=le_drug.transform(test_df['Drug'])\n",
    "        test_df['Disease']=le_dis.transform(test_df['Disease'])\n",
    "        features_cols= test_df.columns.difference(['Drug','Disease','Class'])\n",
    "        X_new=test_df[features_cols].values\n",
    "        y_new=test_df['Class'].values.ravel()\n",
    "        \n",
    "        clf.fit(X,y)\n",
    "\n",
    "        scoring = ['precision', 'recall', 'accuracy', 'roc_auc', 'f1', 'average_precision']\n",
    "        scorers, multimetric = metrics.scorer._check_multimetric_scoring(clf, scoring=scoring)\n",
    "        #print(scorers)\n",
    "        scores = multimetric_score(clf, X_new, y_new, scorers)\n",
    "        print (\"C1\",scores, file=output_f)\n",
    "        results = results.append(scores, ignore_index=True)  \n",
    "        del X, y\n",
    "        del X_new, y_new\n",
    "        del train_df, pairs_train_df\n",
    "        del test_df, pairs_test_df\n",
    "        gc.collect()\n",
    "    \n",
    "    #print numpy.mean(all_auc), numpy.std(all_auc), numpy.mean(all_auprc), numpy.std(all_auprc)\n",
    "    #if output_f is not None:\n",
    "        #output_f.write(\"n_fold\\tn_proportion\\tn_setsel\\tmodel type\\tfeatures\\tdisjoint\\tauc.mean\\tauc.sd\\tauprc.mean\\tauprc.sd\\n\")\n",
    "    #    output_f.write(\"%d\\t%d\\t%d\\t%s\\t%s\\t%d\\t%f\\t%f\\t%f\\t%f\\t%f\\t%f\\n\" % (n_fold, n_proportion, n_setsel, model_type,  \"|\".join(features), disjoint_cv, numpy.mean(all_auc), numpy.std(all_auc), numpy.mean(all_auprc), numpy.std(all_auprc), numpy.mean(all_fs), numpy.std(all_fs)))\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "def getData(goldindfile, drugfeatfiles, diseasefeatfiles, selectedFeatures=None):\n",
    "    if selectedFeatures != None:\n",
    "        selectedFeatures += ['Drug','Disease']\n",
    "\n",
    "    gold_df= pd.read_csv(goldindfile, delimiter='\\t')\n",
    "\n",
    "    drugs=gold_df.Drug.unique()\n",
    "    diseases=gold_df.Disease.unique()\n",
    "\n",
    "    for i,featureFilename in enumerate(drugfeatfiles):\n",
    "        temp=pd.read_csv(featureFilename, delimiter='\\t')\n",
    "        if i != 0:\n",
    "            drug_df=drug_df.merge(temp,on='Drug')\n",
    "            #drug_df=drug_df.merge(temp,how='outer',on='Drug')\n",
    "        else:\n",
    "            drug_df =temp\n",
    "\n",
    "    #drug_df.fillna(0,inplace=True)\n",
    "\n",
    "    if selectedFeatures != None:\n",
    "        drug_feature_names = drug_df.columns.intersection(selectedFeatures)\n",
    "        drug_df=drug_df[drug_feature_names]\n",
    "\n",
    "    for i,featureFilename in enumerate(diseasefeatfiles):\n",
    "        temp=pd.read_csv(featureFilename, delimiter='\\t')\n",
    "        if i != 0:\n",
    "            disease_df=disease_df.merge(temp,on='Disease')\n",
    "        else:\n",
    "            disease_df =temp\n",
    "\n",
    "    if selectedFeatures != None:\n",
    "        disease_feature_names = disease_df.columns.intersection(selectedFeatures)\n",
    "        disease_df=disease_df[disease_feature_names]\n",
    "\n",
    "    print (\"number of drugs \",len(drug_df))\n",
    "    print (\"number of diseases \",len( disease_df))\n",
    "    commonDrugs=set(drug_df['Drug'].unique()).intersection(set(drugs))\n",
    "    commonDiseases=set(disease_df['Disease'].unique()).intersection(set(diseases))\n",
    "\n",
    "    gold_df=gold_df.loc[gold_df['Drug'].isin(commonDrugs) & gold_df['Disease'].isin(commonDiseases) ] \n",
    "    drug_df=drug_df.loc[drug_df['Drug'].isin(gold_df.Drug.unique())]\n",
    "    disease_df=disease_df.loc[disease_df['Disease'].isin(gold_df.Disease.unique())]\n",
    "    print (\"#drugs in gold \",len( drugs))\n",
    "    print (\"#diseases in gold \",len( diseases))\n",
    "    print (\"Used indications \",len(gold_df))\n",
    "       \n",
    "    return gold_df, drug_df, disease_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_groups(idx_true_list, idx_false_list, n_subset, n_proportion=1, shuffle=False):\n",
    "    \"\"\"\n",
    "    >>> a = get_groups([[13,2,1],[14,3,4],[15,5,6]], [[7,8],[9,10],[11,12]], 1, 1, True)\n",
    "    \"\"\"\n",
    "    n = len(idx_true_list)\n",
    "    if n_subset != -1:\n",
    "        n_subset = n_subset / n \n",
    "    for i in range(n):\n",
    "        if n_subset == -1: # use all data\n",
    "            if n_proportion < 1:\n",
    "                indices_test = idx_true_list[i] + idx_false_list[i]\n",
    "            else:\n",
    "                indices_test = idx_true_list[i] + random.sample( idx_false_list[i], n_proportion * len(idx_true_list[i]))\n",
    "        else:\n",
    "            if shuffle:\n",
    "                indices_test = random.sample(idx_true_list[i], n_subset) + random.sample(idx_false_list[i], n_proportion * n_subset)\n",
    "            else:\n",
    "                indices_test = idx_true_list[i][:n_subset] + idx_false_list[i][:(n_proportion * n_subset)]\n",
    "        indices_train = []\n",
    "        for j in range(n):\n",
    "            if i == j:\n",
    "                continue\n",
    "            if n_subset == -1: # use all data\n",
    "                if n_proportion < 1:\n",
    "                    indices_train += idx_true_list[j] + idx_false_list[j]\n",
    "                else:\n",
    "                    indices_train += idx_true_list[j] + random.sample( idx_false_list[j], n_proportion * len(idx_true_list[j]))\n",
    "            else:\n",
    "                if shuffle:\n",
    "                    indices_train += random.sample(idx_true_list[j], n_subset) + random.sample(idx_false_list[j], n_proportion * n_subset)\n",
    "                else:\n",
    "                    indices_train += idx_true_list[j][:n_subset] + idx_false_list[j][:(n_proportion * n_subset)]\n",
    "        yield indices_train, indices_test\n",
    " \n",
    "def balance_data_and_get_cv(pairs, classes, n_fold, n_proportion, n_subset=-1, disjoint=False, n_seed = None):\n",
    "    \"\"\"\n",
    "    pairs: all possible drug-disease pairs\n",
    "    classes: labels of these drug-disease associations (1: known, 0: unknown)\n",
    "    n_fold: number of cross-validation folds\n",
    "    n_proportion: proportion of negative instances compared to positives (e.g.,\n",
    "    2 means for each positive instance there are 2 negative instances)\n",
    "    n_subset: if not -1, it uses a random subset of size n_subset of the positive instances\n",
    "    (to reduce the computational time for large data sets)\n",
    "    disjoint: whether the cross-validation folds contain overlapping drugs (True) \n",
    "    or not (False)\n",
    "    This function returns (pairs, classes, cv) after balancing the data and\n",
    "    creating the cross-validation folds. cv is the cross validation iterator containing \n",
    "    train and test splits defined by the indices corresponding to elements in the \n",
    "    pairs and classes lists.\n",
    "    \"\"\"\n",
    "    classes = numpy.array(classes)\n",
    "    pairs = numpy.array(pairs)\n",
    "    idx_true_list = [ list() for i in range(n_fold) ]\n",
    "    idx_false_list = [ list() for i in range(n_fold) ]\n",
    "    if disjoint:\n",
    "        i_random = random.randint(0,100) # for getting the shuffled drug names in the same fold below\n",
    "        for idx, (pair, class_) in enumerate(zip(pairs, classes)):\n",
    "            drug, disease = pair\n",
    "            if disjoint == 1:\n",
    "                i = sum([ord(c) + i_random for c in drug]) % n_fold\n",
    "            else:\n",
    "                i = sum([ord(c) + i_random for c in disease]) % n_fold\n",
    "            if class_ == 0:\n",
    "                idx_false_list[i].append(idx)\n",
    "            else:\n",
    "                idx_true_list[i].append(idx)\n",
    "        #print \"+/-:\", map(len, idx_true_list), map(len, idx_false_list),n_fold,n_proportion, n_subset\n",
    "        cv = get_groups(idx_true_list, idx_false_list, n_subset, n_proportion, shuffle=True)\n",
    "    else:\n",
    "        indices_true = numpy.where(classes == 1)[0]\n",
    "        indices_false = numpy.where(classes == 0)[0]\n",
    "        if n_subset == -1: # use all data\n",
    "            n_subset = len(classes)\n",
    "        indices_true = indices_true[:n_subset]\n",
    "        numpy.random.shuffle(indices_false)\n",
    "        if n_proportion < 1:\n",
    "            indices = indices_false\n",
    "        else:\n",
    "            #indices = numpy.random.choice(indices_false,size=(n_proportion*indices_true.shape[0]))\n",
    "            indices = indices_false[:(n_proportion*indices_true.shape[0])]\n",
    "        #print \"+/-:\", len(indices_true), len(indices), len(indices_false)\n",
    "        pairs = numpy.concatenate((pairs[indices_true], pairs[indices]), axis=0)\n",
    "        classes = numpy.concatenate((classes[indices_true], classes[indices]), axis=0) \n",
    "        cv = cross_validation.StratifiedKFold(classes, n_folds=n_fold, shuffle=True, random_state=n_seed)\n",
    "    return pairs, classes, cv\n",
    "\n",
    "def get_classification_model(model_type, model_fun = None, n_seed = None):\n",
    "    \"\"\"\n",
    "    model_type: custom | svm | logistic | knn | tree | rf | gbc\n",
    "    model_fun: the function implementing classifier when the model_type is custom\n",
    "    The allowed values for model_type are custom, svm, logistic, knn, tree, rf, gbc\n",
    "    corresponding to custom model provided in model_fun by the user or the default \n",
    "    models in Scikit-learn for support vector machine, k-nearest-neighbor, \n",
    "    decision tree, random forest and gradient boosting classifiers, respectively. \n",
    "    Returns the classifier object that provides fit and predict_proba methods.\n",
    "    \"\"\"\n",
    "    if model_type == \"svm\":\n",
    "        clf = svm.SVC(kernel='linear', probability=True, C=1)\n",
    "    elif model_type == \"logistic\":\n",
    "        clf = linear_model.LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, random_state=n_seed) #, fit_intercept=True, intercept_scaling=1, class_weight=None, solver='liblinear', max_iter=100, multi_class='ovr', verbose=0, warm_start=False, n_jobs=1)\n",
    "    elif model_type == \"knn\":\n",
    "        clf = neighbors.KNeighborsClassifier(n_neighbors=5) #weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=1)\n",
    "    elif model_type == \"tree\":\n",
    "        clf = tree.DecisionTreeClassifier(criterion='gini', random_state=n_seed) #splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, max_leaf_nodes=None, class_weight=None, presort=False)\n",
    "    elif model_type == \"rf\":\n",
    "        clf = ensemble.RandomForestClassifier(n_estimators=100, criterion='gini', random_state=n_seed) #, max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, bootstrap=True, oob_score=False, n_jobs=1, verbose=0, warm_start=False, class_weight=None)\n",
    "    elif model_type == \"gbc\":\n",
    "        clf = ensemble.GradientBoostingClassifier(n_estimators= 100, max_depth= 5, random_state = n_seed, max_features=0.9)\n",
    "        #clf = ensemble.GradientBoostingClassifier(n_estimators=100, loss='deviance', learning_rate=0.1, subsample=1.0, random_state=n_seed) #, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, init=None, max_features=None, verbose=0, max_leaf_nodes=None, warm_start=False, presort='auto')\n",
    "    elif model_type == \"custom\":\n",
    "        if fun is None:\n",
    "            raise ValueError(\"Custom model requires fun argument to be defined!\")\n",
    "        clf = fun\n",
    "    else:\n",
    "        raise ValueError(\"Uknown model type: %s!\" % model_type)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    \n",
    "    goldindfile=args[\"goldindications\"]\n",
    "    model_type=args[\"modelfile\"]\n",
    "    disjoint=int(args[\"disjoint\"])\n",
    "    output_file_name=args[\"output\"]\n",
    "    drugfeatfiles=args[\"drugfeat\"]\n",
    "    diseasefeatfiles=args[\"diseasefeat\"]\n",
    "    n_proportion = int(args[\"proportion\"])\n",
    "    #Get parameters\n",
    "    n_seed = 205\n",
    "    #random.seed(n_seed) # for reproducibility\n",
    "    n_subset =-1\n",
    "\n",
    "    output_file=open( output_file_name,'a')\n",
    "\n",
    "    #fs=open(\"../data/importantFeatures.txt\")\n",
    "    #selectedFeatures =[]\n",
    "    #for l in csv.reader(fs):\n",
    "    #    selectedFeatures.append(l[0])\n",
    "    \n",
    "    selectedFeatures =None\n",
    "    gold_df, drug_df, disease_df = getData(goldindfile, drugfeatfiles, diseasefeatfiles, selectedFeatures)\n",
    "    \n",
    "    features=[ fn[fn.index('-')+1:fn.index('.txt')] for fn in drugfeatfiles+diseasefeatfiles]\n",
    "\n",
    "    \n",
    "    drugDiseaseKnown = set([tuple(x) for x in  gold_df[['Drug','Disease']].values])\n",
    "\n",
    "    commonDrugs=drug_df['Drug'].unique()\n",
    "    commonDiseases=disease_df['Disease'].unique()\n",
    "    pairs=[]\n",
    "    classes=[]\n",
    "    print (\"commonDiseases\",len(commonDiseases))\n",
    "    print (\"commonDrugs\",len(commonDrugs))\n",
    "    for dr in commonDrugs:\n",
    "        for di in commonDiseases:\n",
    "            if (dr,di)  in drugDiseaseKnown:\n",
    "                cls=1\n",
    "            else:\n",
    "                cls=0\n",
    "            pairs.append((dr,di))\n",
    "            classes.append(cls)\n",
    "\n",
    "    n_run = 10\n",
    "    n_seed = 205\n",
    "    n_fold =10\n",
    "    model_fun=None\n",
    "    n_subset=-1\n",
    "\n",
    "    results_runs = pd.DataFrame()\n",
    "    output_file.write(\"n_fold\\tn_proportion\\tn_setsel\\tmodel type\\tfeatures\\tdisjoint\\tauc.mean\\tauc.sd\\tauprc.mean\\tauprc.sd\\tf-score.mean\\tf-score.sd\\n\")\n",
    "    for i in range(n_run):\n",
    "        if n_seed is not None:\n",
    "            n_seed += i\n",
    "            random.seed(n_seed)\n",
    "            numpy.random.seed(n_seed)\n",
    "        pairs_, classes_, cv = balance_data_and_get_cv(pairs, classes, n_fold, n_proportion, n_subset, disjoint, n_seed )\n",
    "        results = runModel( pairs_, classes_, drug_df, disease_df, cv, n_subset, n_proportion, n_fold, model_type, model_fun, features, disjoint, n_seed, 1, verbose=True, output_f=output_file)\n",
    "        results_runs = results_runs.append(results.mean(), ignore_index=True)\n",
    "\n",
    "    print (\"Runs\",results_runs.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of drugs  816\n",
      "number of diseases  1393\n",
      "#drugs in gold  1594\n",
      "#diseases in gold  1611\n",
      "Used indications  4715\n",
      "commonDiseases 1103\n",
      "commonDrugs 788\n",
      "Runs accuracy             0.769438\n",
      "average_precision    0.768296\n",
      "f1                   0.509465\n",
      "precision            0.864017\n",
      "recall               0.366252\n",
      "roc_auc              0.850286\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "args = dict()\n",
    "args[\"goldindications\"] = \"data/input/unified-gold-standard-umls.txt\" \n",
    "args[\"modelfile\"] = \"rf\"\n",
    "args[\"disjoint\"] = 1\n",
    "args[\"output\"] = \"data/output/completeset_unified_validation.txt\"\n",
    "args[\"drugfeat\"] = [\"data/features/drugs-targets.txt\",\"data/features/drugs-fingerprint.txt\",\"data/features/drugs-sider-se.txt\"]\n",
    "args[\"diseasefeat\"] = [\"data/features/diseases-ndfrt-meddra.txt\"]\n",
    "args[\"proportion\"]= 2\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "goldindi =pd.read_csv('data/input/predict-omim-drugbank.txt',delimiter='\\t') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "goldindi['Class']=1\n",
    "goldindi.Class = goldindi.Class.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "pivot() got an unexpected keyword argument 'fill_value'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-d127dbbf74f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mgoldindi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Drug'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Disease'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: pivot() got an unexpected keyword argument 'fill_value'"
     ]
    }
   ],
   "source": [
    "matrix =goldindi.pivot(index='Drug', columns='Disease')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix = matrix['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Disease</th>\n",
       "      <th>102100</th>\n",
       "      <th>102300</th>\n",
       "      <th>102400</th>\n",
       "      <th>102500</th>\n",
       "      <th>103100</th>\n",
       "      <th>103780</th>\n",
       "      <th>104130</th>\n",
       "      <th>104300</th>\n",
       "      <th>106400</th>\n",
       "      <th>107320</th>\n",
       "      <th>...</th>\n",
       "      <th>607682</th>\n",
       "      <th>607685</th>\n",
       "      <th>607850</th>\n",
       "      <th>608033</th>\n",
       "      <th>608088</th>\n",
       "      <th>608105</th>\n",
       "      <th>608217</th>\n",
       "      <th>608320</th>\n",
       "      <th>608583</th>\n",
       "      <th>608622</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drug</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DB04844</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DB04861</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DB05259</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DB06285</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DB06287</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 313 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Disease  102100  102300  102400  102500  103100  103780  104130  104300  \\\n",
       "Drug                                                                      \n",
       "DB04844     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "DB04861     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "DB05259     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "DB06285     NaN     NaN     NaN     1.0     NaN     NaN     NaN     NaN   \n",
       "DB06287     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "Disease  106400  107320   ...    607682  607685  607850  608033  608088  \\\n",
       "Drug                      ...                                             \n",
       "DB04844     NaN     NaN   ...       NaN     NaN     NaN     NaN     NaN   \n",
       "DB04861     NaN     NaN   ...       NaN     NaN     NaN     NaN     NaN   \n",
       "DB05259     NaN     NaN   ...       NaN     NaN     NaN     NaN     NaN   \n",
       "DB06285     NaN     NaN   ...       NaN     NaN     NaN     NaN     NaN   \n",
       "DB06287     NaN     NaN   ...       NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "Disease  608105  608217  608320  608583  608622  \n",
       "Drug                                             \n",
       "DB04844     NaN     NaN     NaN     NaN     NaN  \n",
       "DB04861     NaN     NaN     NaN     NaN     1.0  \n",
       "DB05259     NaN     NaN     NaN     NaN     NaN  \n",
       "DB06285     NaN     NaN     NaN     NaN     NaN  \n",
       "DB06287     NaN     NaN     NaN     NaN     NaN  \n",
       "\n",
       "[5 rows x 313 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix[matrix.isna()]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix.to_csv('/home/remzi/drug-repurpose/repurpose/data/predict_drug_disease.dat', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
